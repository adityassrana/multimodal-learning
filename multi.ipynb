{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise multimodal recognition: RGB-D scene recognition\n",
    "\n",
    "This exercise consists of three parts: two tutorials and the deliverable. The students must modify the code of the tutorial part, and write and discuss the results in the deliverable part that will be used to evaluate the exercise.\n",
    "\n",
    "If you are not familiar with jupyter notebooks please check __[this tutorial](https://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/What%20is%20the%20Jupyter%20Notebook.html)__ first.\n",
    "\n",
    "# Part 2 (tutorial): RGB-D baseline\n",
    "\n",
    "If you haven followed the tutorial related with single modality, please run **single.ipynb** first for the first part.\n",
    "\n",
    "In this tutorial, you will build a two-branch RGB-D network using PyTorch. The code is loosely based on the __[PyTorch transfer learning tutorial](http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)__. Just execute the code sequentially, paying attention to the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import RGBDutils\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "We will use torchvision, torch.utils.data and RGBDutils packages for loading the\n",
    "data. The dataset is structured hierarchically in splits\\modalities\\classes (check the folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "RGB_AVG = [0.485, 0.456, 0.406] # Default ImageNet ILSRVC2012\n",
    "RGB_STD = [0.229, 0.224, 0.225] # Default ImageNet ILSRVC2012\n",
    "DEPTH_AVG = [0.485, 0.456, 0.406] # Default ImageNet ILSRVC2012\n",
    "DEPTH_STD = [0.229, 0.224, 0.225] # Default ImageNet ILSRVC2012\n",
    "data_transforms = {\n",
    "    'train': RGBDutils.Compose([\n",
    "        RGBDutils.RandomResizedCrop(227),\n",
    "        RGBDutils.RandomHorizontalFlip(),\n",
    "        RGBDutils.ToTensor(),\n",
    "        RGBDutils.Normalize(RGB_AVG, RGB_STD, DEPTH_AVG, DEPTH_STD)\n",
    "    ]),\n",
    "    'val': RGBDutils.Compose([\n",
    "        RGBDutils.Resize(256),\n",
    "        RGBDutils.CenterCrop(227),\n",
    "        RGBDutils.ToTensor(),\n",
    "        RGBDutils.Normalize(RGB_AVG, RGB_STD, DEPTH_AVG, DEPTH_STD)\n",
    "    ]),\n",
    "    'test': RGBDutils.Compose([\n",
    "        RGBDutils.Resize(256),\n",
    "        RGBDutils.CenterCrop(227),\n",
    "        RGBDutils.ToTensor(),\n",
    "        RGBDutils.Normalize(RGB_AVG, RGB_STD, DEPTH_AVG, DEPTH_STD)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Path to the dataset\n",
    "# data_dir = '/home/mcv/datasets/sunrgbd_lite'\n",
    "data_dir = 'sunrgbd_lite'\n",
    "\n",
    "# Preparing dataset and dataloaders\n",
    "partitions = ['train', 'val', 'test']\n",
    "image_datasets = {x: RGBDutils.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in partitions}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in partitions}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in partitions}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize a few samples**\n",
    "\n",
    "Let's visualize a few RGB-D pairs so as to RGB-D data and data augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data and visualize the first four pairs\n",
    "inputsRGB, inputsDepth, classes = next(iter(dataloaders['train']))\n",
    "inputsRGB, inputsDepth, classes = inputsRGB[0:4], inputsDepth[0:4], classes[0:4]\n",
    "\n",
    "# Make a grid from batch\n",
    "outRGB = torchvision.utils.make_grid(inputsRGB)\n",
    "outDepth = torchvision.utils.make_grid(inputsDepth)\n",
    "\n",
    "RGBDutils.imshow(outRGB, outDepth, title=[class_names[x] for x in classes],concat_vert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Details:\n",
    "\n",
    "-  Uses Adam algorithm for gradient descent.\n",
    "-  Early stoping using best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            print('Phase %s' % phase)\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs_rgb, inputs_hha, labels = data\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs_rgb = Variable(inputs_rgb.cuda())\n",
    "                    inputs_hha = Variable(inputs_hha.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs_rgb, inputs_hha, labels = Variable(inputs_hha), Variable(inputs_hha), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model((inputs_rgb, inputs_hha))\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                # running_loss += loss.data[0] * inputs_rgb.size(0) # Pytorch 0.4\n",
    "                running_loss += loss.data.item() * inputs_rgb.size(0) # Pytorch 1\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, a function to evaluate the model on a particular set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, partition, criterion):\n",
    "    since = time.time()\n",
    "\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloaders[partition]:\n",
    "        # get the inputs\n",
    "        inputs_rgb, inputs_hha, labels = data\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs_rgb = Variable(inputs_rgb.cuda())\n",
    "            inputs_hha = Variable(inputs_hha.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs_rgb, inputs_hha, labels = Variable(inputs_hha), Variable(inputs_hha), Variable(labels)\n",
    "\n",
    "        # forward\n",
    "        outputs = model((inputs_rgb, inputs_hha))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        # running_loss += loss.data[0] * inputs_rgb.size(0) # Pytorch 0.4\n",
    "        running_loss += loss.data.item() * inputs_rgb.size(0) # Pytorch 1\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_loss = running_loss / dataset_sizes[partition]\n",
    "    test_acc = running_corrects / dataset_sizes[partition]\n",
    "\n",
    "    \n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Tested in {:.0f}m {:.0f}s Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60, test_loss, test_acc))\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the RGB-D model\n",
    "----------------------\n",
    "\n",
    "The architecture of the network is shown in the following figure:\n",
    "<img src=\"figures/rgbd_network.png\" />\n",
    "\n",
    "The following code creates the RGB-D network by instantiating two AlexNets, that are combined using concatenation just before the classifier. There are some tricky steps due to the way the pretrained AlexNet is implemented in PyTorch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PyTorch every network is implementd as a nn.Module\n",
    "class RGBDnet(nn.Module):\n",
    "    # The parameters are initialized in __init__(self, ...)\n",
    "    def __init__(self, num_classes):\n",
    "        super(RGBDnet, self).__init__()\n",
    "        \n",
    "        # RGB branch\n",
    "        model_rgb = torchvision.models.alexnet(pretrained=True)\n",
    "        self.rgb_convs = model_rgb.features\n",
    "        c = model_rgb.classifier\n",
    "        self.rgb_fcs = nn.Sequential(c[0],c[1],c[2],c[3],c[4],c[5])\n",
    "        num_ftrs_rgb = c[4].out_features\n",
    "\n",
    "        # HHA branch\n",
    "        model_hha = torchvision.models.alexnet(pretrained=True)\n",
    "        self.hha_convs = model_hha.features\n",
    "        c = model_hha.classifier\n",
    "        self.hha_fcs = nn.Sequential(c[0],c[1],c[2],c[3],c[4],c[5])\n",
    "        f = model_hha.features\n",
    "        c = model_hha.classifier\n",
    "        num_ftrs_hha = c[4].out_features\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(num_ftrs_rgb+num_ftrs_hha, num_classes)\n",
    "\n",
    "    # The data flow is defined in forward. No need to specify backward operations (PyTorch takes care of them)\n",
    "    def forward(self, x):\n",
    "        x_rgb = self.rgb_convs(x[0])\n",
    "        x_rgb = x_rgb.view(x_rgb.size(0), 256 * 6 * 6)\n",
    "        x_hha = self.hha_convs(x[1])\n",
    "        x_hha = x_hha.view(x_hha.size(0), 256 * 6 * 6)\n",
    "        x_rgb = self.rgb_fcs(x_rgb)\n",
    "        x_hha = self.hha_fcs(x_hha)\n",
    "        x = torch.cat((x_rgb, x_hha), 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "num_classes = len(class_names)\n",
    "model = RGBDnet(num_classes=num_classes)\n",
    "\n",
    "# You can visualize the resulting network\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the training/fine tuning parameters\n",
    "----------------------\n",
    "\n",
    "The following code creates the optimization criterio and set per-layer training rates to better control the fine tuning and training process. We use a very simple model in which all layers are frozen except the last fully connected one, i.e. the classifier, so it should be easy to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the learning rate\n",
    "for param in model.parameters(): # Freeze all parameters by default\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate =0.001\n",
    "    \n",
    "perlayer_optim = [\n",
    "    {'params': model.rgb_convs[0].parameters(), 'lr': 0.00}, # conv1 RGB\n",
    "    {'params': model.rgb_convs[3].parameters(), 'lr': 0.00}, # conv2 RGB\n",
    "    {'params': model.rgb_convs[6].parameters(), 'lr': 0.00}, # conv3 RGB\n",
    "    {'params': model.rgb_convs[8].parameters(), 'lr': 0.00}, # conv4 RGB\n",
    "    {'params': model.rgb_convs[10].parameters(), 'lr': 0.00}, # conv5 RGB\n",
    "    {'params': model.rgb_fcs[1].parameters(), 'lr': 0.00}, # fc6 RGB\n",
    "    {'params': model.rgb_fcs[4].parameters(), 'lr': 0.00}, # fc7 RGB\n",
    "    {'params': model.hha_convs[0].parameters(), 'lr': 0.00}, # conv1 HHA\n",
    "    {'params': model.hha_convs[3].parameters(), 'lr': 0.00}, # conv2 HHA\n",
    "    {'params': model.hha_convs[6].parameters(), 'lr': 0.00}, # conv3 HHA\n",
    "    {'params': model.hha_convs[8].parameters(), 'lr': 0.00}, # conv4 HHA\n",
    "    {'params': model.hha_convs[10].parameters(), 'lr': 0.00}, # conv5 HHA\n",
    "    {'params': model.hha_fcs[1].parameters(), 'lr': 0.00}, # fc6 HHA\n",
    "    {'params': model.hha_fcs[4].parameters(), 'lr': 0.00}, # fc7 HHA\n",
    "    {'params': model.classifier.parameters(), 'lr': 0.001} # fc8\n",
    "]\n",
    "for param in itertools.chain(model.rgb_convs[0].parameters(),model.rgb_convs[3].parameters(),\n",
    "                             model.rgb_convs[6].parameters(),model.rgb_convs[8].parameters(),\n",
    "                             model.rgb_convs[10].parameters(),model.rgb_fcs[1].parameters(),\n",
    "                             model.rgb_fcs[4].parameters(),\n",
    "                             model.hha_convs[0].parameters(),model.hha_convs[3].parameters(),\n",
    "                             model.hha_convs[6].parameters(),model.hha_convs[8].parameters(),\n",
    "                             model.hha_convs[10].parameters(),model.hha_fcs[1].parameters(),\n",
    "                             model.hha_fcs[4].parameters(),\n",
    "                             model.classifier.parameters()):\n",
    "    param.requires_grad = True\n",
    "    \n",
    "    \n",
    "optimizer = torch.optim.Adam(perlayer_optim, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model\n",
    "-----------------\n",
    "\n",
    "It shouldn't take more than 2 mins to train with the GPU in the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = train_model(model, criterion, optimizer, None, num_epochs=25)\n",
    "    \n",
    "# Evaluate\n",
    "train_acc, _ = evaluate_model(model, 'train', criterion)\n",
    "val_acc, _ = evaluate_model(model, 'val', criterion)\n",
    "test_acc, _ = evaluate_model(model, 'test', criterion)\n",
    "print('Accuracy. Train: %1.2f%% val: %1.2f%% test: %1.2f%%' % \n",
    "      (train_acc*100, val_acc*100, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (deliverable)\n",
    "\n",
    "This part will be evaluated as deliverable. Please check you include the required results and information. In principle I don't intent to run your code, just check your numbers and descriptions.\n",
    "\n",
    "* Comparison of RGB, HHA and RGB-D baselines. Include a table with the train, validation and test average accuracies (and standard deviations) over 5 runs for each case (RGB only, HHA only and RGB-D).\n",
    "* Description of the improvements of the RGB-D network, experimental results and discussion (0.25 points)\n",
    "* Team work: description of the contribution of each member of the team.\n",
    "\n",
    "The maximum of the exercise is 0.5 points.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
